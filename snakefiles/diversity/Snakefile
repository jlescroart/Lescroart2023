### Snakefile for diversity pipeline, with associated file config.yaml
### Calculating diversity statistics from genomic fragments (multiple alignment files) in fasta format
### Load associated environment with $ conda activate diversity
### Author Jonas Lescroart

### Packages
import pandas as pd
import re
from pathlib import Path
import skbio

### Configuration
configfile: "config_Lge-1.yaml"

### Functions
def strip_ext(file_str): 
    bits = file_str.split(".") 
    if re.match("gz", bits[-1]): 
        bits = bits[:-1] 
    if re.match("fasta|fa|fna", bits[-1]): 
        bits = bits[:-1] 
    return ".".join(bits) 

def csv2nwk(infile_csv, outfile_nwk):
    #This function applies the skbio.nj function to an input distance matrix in .csv and outputs a NJ tree in .nwk. It takes the name of the input and output files.
    #Requires import of skbio, and pandas as pd.
    #Update 23JUL21: prints 'NaN' in newick for empty input matrices.
    csv = pd.read_csv(infile_csv, sep = ",", index_col = 0, na_values = ["None"])
    if csv.isnull().values.any():
        with open(outfile_nwk, "w") as nwk:
            nwk.write("NaN")
    else:
        distance_matrix = skbio.DistanceMatrix(csv, ids = csv.index.values.tolist())
        nj_newick = skbio.nj(distance_matrix, result_constructor=str)
        with open(outfile_nwk, "w") as nwk:
            nwk.write(nj_newick)

### Variables
metadata = pd.read_csv(config["metadata"], sep = "\t", engine = "python", encoding = "latin-1").set_index("unique_id", drop = False)
unique_id = [id for id in metadata["unique_id"].astype(str).tolist()]

unique_id.remove("mLynCan4") # Temporary skipping Lynx bc data is faulty
unique_id.remove("bLge-252")

genomic_fragments = pd.read_csv(config["input"]["filenames"], names = ["file"], engine = "python")
unique_gf = [strip_ext(gf) for gf in genomic_fragments["file"].astype(str).tolist()]

autosomes = pd.read_csv(config["input"]["auto"], header = None, engine = "python", encoding = "latin-1")
autosomes = [chr for chr in autosomes[0].astype(str).tolist()]

### Rules
rule all:
    input:
        #expand("{dir}/pairwise_pi/fragments/{{gf}}.nwk".format(dir = config["output"]["fragments_dir"]), gf = unique_gf),
        #"{dir}/pairwise_pi/all_NJ.nwk".format(dir = config["output"]["fragments_dir"]),
        #"{dir}/pairwise_pi/average_pairwise_pi.nwk".format(dir = config["output"]["fragments_dir"]),
        "{dir}/leopardus_heterozygosity.txt".format(dir = config["output"]["heterozygosity"]),
        expand("{dir}/{{id}}.summary.txt".format(dir = config["output"]["roh"]), id = unique_id),
        expand("{dir}/{{id}}.final.txt".format(dir = config["output"]["demography"]), id = unique_id)

rule pairwise_pi:
    input:
        maf = "{dir}/{{gf}}.fasta".format(dir = config["input"]["fragments_dir"])
    output:
        csv = temp("{dir}/pairwise_pi/fragments/{{gf}}_unique_id.csv".format(dir = config["output"]["fragments_dir"]))
    params:
        script = config["scripts"]["pairwise_pi"]
    shell:
        "python3 {params.script} {input.maf} > {output.csv}"

rule unique_id2figure_id_pairwise_pi:
    input:
        csv = "{dir}/pairwise_pi/fragments/{{gf}}_unique_id.csv".format(dir = config["output"]["fragments_dir"])
    output:
        csv = "{dir}/pairwise_pi/fragments/{{gf}}.csv".format(dir = config["output"]["fragments_dir"])
    run:
        with open(output.csv, "w") as out:
            for line in shell("cat {input.csv}", iterable = True):
                for id in unique_id:
                    line = re.sub(id, metadata["figure_id"][id], line)
                out.write(line + "\n")

rule filenames:
    input:
        csv = expand("{dir}/pairwise_pi/fragments/{{gf}}.csv".format(dir = config["output"]["fragments_dir"]), gf = unique_gf)
    output:
        txt = "{dir}/pairwise_pi/filenames.txt".format(dir = config["output"]["fragments_dir"])
    params:
        dir = "{dir}/pairwise_pi/fragments/".format(dir = config["output"]["fragments_dir"])
    shell:
        "find {params.dir} -type f -name '*.csv' > {output.txt}"

#this needs work
rule pairwise_pi_plot:
    input:
        csv = expand("{dir}/pairwise_pi/fragments/{{gf}}.csv".format(dir = config["output"]["fragments_dir"]), gf = unique_gf),
        txt = "{dir}/pairwise_pi/filenames.txt".format(dir = config["output"]["fragments_dir"])
    output:
        csv = "{dir}/pairwise_pi/average_pairwise_pi.csv".format(dir = config["output"]["fragments_dir"])
    params:
        script = config["scripts"]["pairwise_pi_plot"]
    shell:
        "python3 {params.script} --list {input.txt} --output {output.csv}"

rule csv2nwk_average:
    input:
        csv = "{dir}/pairwise_pi/average_pairwise_pi.csv".format(dir = config["output"]["fragments_dir"])
    output:
        nwk = "{dir}/pairwise_pi/average_pairwise_pi.nwk".format(dir = config["output"]["fragments_dir"])
    run:
        csv2nwk(input.csv, output.nwk)

### Local NJ trees part
rule csv2nwk_average as csv2nwk_fragments with:
    input:
        csv = "{dir}/pairwise_pi/fragments/{{gf}}.csv".format(dir = config["output"]["fragments_dir"])
    output:
        nwk = "{dir}/pairwise_pi/fragments/{{gf}}.nwk".format(dir = config["output"]["fragments_dir"])

rule cat_nwk:
    input:
        nwk = expand("{dir}/pairwise_pi/fragments/{{gf}}.nwk".format(dir = config["output"]["fragments_dir"]), gf = unique_gf)
    output:
        nwk = "{dir}/pairwise_pi/all_NJ.nwk".format(dir = config["output"]["fragments_dir"])
    params:
        dir = "{dir}/pairwise_pi/fragments/".format(dir = config["output"]["fragments_dir"])
    shell:
        "find {params.dir} -type f -name '*.nwk' | xargs awk '{{print}}' > {output.nwk}"
# trees need to be rooted to outgroup with nw_reroot all_nj.nwk Puma_concolor


### Rules for heterozygosity. Needs ANGSD v0.921, doesn't work with more recent versions.
rule gunzip:
    input:
        gz = config["ref"]["file"]
    output:
        fna = strip_ext(config["ref"]["file"]) + ".fna"
    shell:
        "gunzip -c {input.gz} > {output.fna}"

rule angsd:
    input:
        bam = "{dir}/{{id}}.filtered.bam".format(dir = config["input"]["bam_dir"]), 
        fna = strip_ext(config["ref"]["file"]) + ".fna"
    output:
        idx = "{dir}/{{id}}.saf.idx".format(dir = config["output"]["heterozygosity"])
    threads: 4
    params:
        id = "{dir}/{{id}}".format(dir = config["output"]["heterozygosity"]),
        dir = config["output"]["heterozygosity"],
        rf = config["angsd"]["rf"]
    shell:
        "mkdir -p {params.dir} && " + # Not sure if angsd can create the directory by itself from the -out flag
        "angsd -i {input.bam} -rf {params.rf} -nThreads {threads} -ref {input.fna} -anc {input.fna} -doSaf 1 -GL 1 -C 50 -fold 1 -minQ 20 -minmapq 30 -out {params.id}"

rule angsd_realsfs:
    input:
        idx = "{dir}/{{id}}.saf.idx".format(dir = config["output"]["heterozygosity"])
    output:
        ml = "{dir}/{{id}}.est.ml".format(dir = config["output"]["heterozygosity"])
    threads: 3
    shell:
        "realSFS {input.idx} -nSites 200000 > {output.ml}"

rule getHetvalues_folded:
    input:
        ml = "{dir}/{{id}}.est.ml".format(dir = config["output"]["heterozygosity"])
    output:
        txt = "{dir}/{{id}}.txt".format(dir = config["output"]["heterozygosity"])
    params:
        script = config["scripts"]["getHetvalues_folded"]
    shell:
        "python {params.script} {input.ml} > {output.txt}"

rule cat:
    input:
        txt = expand("{dir}/{{id}}.txt".format(dir = config["output"]["heterozygosity"]), id = unique_id)
    output:
        txt = temp("{dir}/leopardus_heterozygosity_unique_id.txt".format(dir = config["output"]["heterozygosity"]))
    shell:
        "cat {input.txt} > {output.txt}"

rule unique_id2figure_id_heterozygosity:
    input:
        txt = "{dir}/leopardus_heterozygosity_unique_id.txt".format(dir = config["output"]["heterozygosity"])
    output:
        txt = "{dir}/leopardus_heterozygosity.txt".format(dir = config["output"]["heterozygosity"])
    run:
        with open(output.txt, "w") as out:
            for line in shell("cat {input.txt}", iterable = True):
                for id in unique_id:
                    line = re.sub(id, metadata["figure_id"][id], line)
                out.write(line + "\n")

rule het_plot:
     input:
         txt = "placeholder"
     output:
         pdf = "placeholder"
     params:
         script = "placeholder"
     shell:
         "Rscript {params.script} "

rule rohan:
    input:
        bam = "{dir}/{{id}}.filtered.bam".format(dir = config["input"]["bam_dir"]),
        fna = strip_ext(config["ref"]["file"]) + ".fna",
        txt = config["input"]["auto"]
    output:
        txt = "{dir}/{{id}}.summary.txt".format(dir = config["output"]["roh"])
    threads: 4
    params:
        id = "{dir}/{{id}}".format(dir = config["output"]["roh"]),
        rohan = config["rohan"]["rohan"],
        rohmu = config["rohan"]["rohmu"]
    shell:
        "{params.rohan} --rohmu {params.rohmu} -t {threads} --auto {input.txt} -o {params.id} {input.fna} {input.bam}"

# see also bcftools roh [OPTIONS] file.vcf.gz for ROHs

### Rules for demographic history.
rule snpable:
    input:
        fna = strip_ext(config["ref"]["file"]) + ".fna"
    output:
        bed = "{dir}/mappability/mappable_99.bed.gz".format(dir = config["output"]["demography"]),
        tbi = "{dir}/mappability/mappable_99.bed.gz.tbi".format(dir = config["output"]["demography"]),
        fa = "{dir}/mappability/rawMask_35.fa.gz".format(dir = config["output"]["demography"])
    threads: 10
    params:
        script = config["scripts"]["snpable"],
        script_dir = config["seqbility_dir"],
        dir = "{dir}/mappability".format(dir = config["output"]["demography"])
    shell:
        "cd {params.dir} && bash {params.script} {input.fna} {params.script_dir}"

rule samtools_depth:
    input:
        bam = "{dir}/{{id}}.filtered.bam".format(dir = config["input"]["bam_dir"])
    output:
        txt = temp("{dir}/{{id}}_{{chr}}_depth.txt".format(dir = config["output"]["demography"]))
    params:
        chr = "{chr}"
    shell:
        "samtools depth -r {params.chr} {input.bam} | awk '{{sum += $3}} END {{print sum / NR}}' > {output.txt}"

rule bamCaller:
    input:
        bam = "{dir}/{{id}}.filtered.bam".format(dir = config["input"]["bam_dir"]),
        fna = strip_ext(config["ref"]["file"]) + ".fna",
        txt = "{dir}/{{id}}_{{chr}}_depth.txt".format(dir = config["output"]["demography"])
    output:
        bed = temp("{dir}/{{id}}_{{chr}}_mask.bed.gz".format(dir = config["output"]["demography"])),
        vcf = temp("{dir}/{{id}}_{{chr}}.vcf.gz".format(dir = config["output"]["demography"]))
    params:
        script = config["scripts"]["bamCaller"],
        chr = "{chr}"
    shell:
        "DEPTH=$(cat {input.txt}) && " +
        "samtools mpileup --min-MQ 30 --min-BQ 20 -C 50 -u -r {params.chr} -f {input.fna} {input.bam} | bcftools call -c -V indels | {params.script} $DEPTH {output.bed} | gzip -c > {output.vcf}"

rule multihetsep:
    input:
        ref_bed = "{dir}/mappability/mappable_99.bed.gz".format(dir = config["output"]["demography"]),
        sample_bed = "{dir}/{{id}}_{{chr}}_mask.bed.gz".format(dir = config["output"]["demography"]),
        vcf = "{dir}/{{id}}_{{chr}}.vcf.gz".format(dir = config["output"]["demography"])
    output:
        txt = temp("{dir}/{{id}}_{{chr}}_multihetsep.txt".format(dir = config["output"]["demography"]))
    params:
        script = config["scripts"]["multihetsep"]
    shell:
        "python {params.script} --mask {input.ref_bed} --mask {input.sample_bed} {input.vcf} > {output.txt}"

rule msmc2:
    input:
        txt = expand(config["output"]["demography"] + "/{{id}}_{chr}_multihetsep.txt", chr = autosomes)
    output:
        final_txt = "{dir}/{{id}}.final.txt".format(dir = config["output"]["demography"]),
        loop_txt = temp("{dir}/{{id}}.loop.txt".format(dir = config["output"]["demography"])),
        log = "{dir}/{{id}}.log".format(dir = config["output"]["demography"])
    threads: 4
    params:
        msmc2 = config["msmc2"],
        prefix = "{dir}/{{id}}".format(dir = config["output"]["demography"])
    shell:
        "{params.msmc2} --nrThreads {threads} -o {params.prefix} {input.txt}"
